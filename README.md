# Water Meters Segmentation - Automated ML Pipeline

[![CI Pipeline](https://github.com/Rafallost/Water-Meters-Segmentation-Autimatization/workflows/CI%20Pipeline/badge.svg)](https://github.com/Rafallost/Water-Meters-Segmentation-Autimatization/actions)

**Automated ML training and deployment pipeline for water meter segmentation using U-Net**

This project demonstrates DevOps best practices applied to machine learning, featuring:
- âœ… Automated data validation and versioning
- âœ… Ephemeral infrastructure (70% cost savings)
- âœ… Quality-gated training pipeline (3 attempts per PR)
- âœ… MLflow experiment tracking
- âœ… Infrastructure as Code (Terraform)

**Bachelor's Thesis Project:** "Application of DevOps Techniques in Implementing Automatic CI/CD Process for Training and Versioning AI Models"

---

## ğŸš€ Quick Start

### For Users: Upload New Training Data

```bash
# 1. Add your images and masks
cp /path/to/new/*.jpg WMS/data/training/images/
cp /path/to/new/*.png WMS/data/training/masks/

# 2. Commit and push
git add WMS/data/training/
git commit -m "data: add new training samples"
git push origin HEAD:data/staging  # Magic branch - auto-creates PR

# 3. Wait ~10 minutes for training
# 4. Check PR for training results
# 5. Merge if model improved!
```

**That's it!** The system handles:
- Data validation
- Model training (3 attempts with different seeds)
- Quality comparison against baseline
- Model promotion to MLflow
- Auto-approval if model improves

ğŸ‘‰ **[Full usage guide](docs/USAGE.md)**

---

## ğŸ“š Documentation

**[â†’ Full Documentation Index](docs/README.md)** ğŸ“–

### Quick Access:

| Document | Description | When to Read |
|----------|-------------|--------------|
| **[WORKFLOWS.md](docs/WORKFLOWS.md)** | â­ **Start here!** All pipelines explained | Understanding the system |
| **[USAGE.md](docs/USAGE.md)** | Step-by-step how-to guide | Daily operations |
| **[ARCHITECTURE.md](docs/ARCHITECTURE.md)** | System design & components | Deep dive |
| **[BRANCH_PROTECTION.md](docs/BRANCH_PROTECTION.md)** | GitHub setup guide | One-time setup |

**For Developers:**
- [Implementation Plan](devops/PLAN.md) - Development phases
- [Terraform Docs](devops/terraform/README.md) - Infrastructure
- [Tests Guide](WMS/tests/README.md) - Unit tests

**For AI Assistants:**
- [CLAUDE.md](devops/CLAUDE.md) - Project context and rules

---

## ğŸ—ï¸ System Overview

```
User â†’ Upload Data â†’ Data QA â†’ Training (EC2 auto-start)
  â†’ Quality Gate â†’ Model Promotion â†’ EC2 auto-stop
  â†’ Merge PR â†’ Deploy (future)
```

### Key Features

**Ephemeral Infrastructure**
- EC2 instance only runs during training (~10 min)
- Cost: ~$4/month instead of ~$18/month (70% savings)
- Fully automated start/stop via GitHub Actions

**Quality-Gated Training**
- 3 training attempts per PR (different random seeds)
- Compares to baseline: Dice 0.9275, IoU 0.8865
- Auto-promotes best model to MLflow Production
- Auto-approves PR if model improves

**Data Versioning**
- DVC integration with S3 backend
- Git tracks metadata, S3 stores large files
- POC mode: Small datasets tracked in Git directly

**Experiment Tracking**
- MLflow server on EC2
- Tracks metrics, hyperparameters, artifacts
- Model registry with versioning (Staging/Production)

---

## ğŸ§  Model Architecture

**U-Net for Semantic Segmentation**

```
Input: 512Ã—512 RGB image (water meter photo)
  â†“
Encoder (4 levels): 16â†’32â†’64â†’128â†’256 channels
  â†“
Bottleneck: 256 channels
  â†“
Decoder (4 levels) + skip connections
  â†“
Output: 512Ã—512 binary mask (meter region)
```

| Metric | Baseline (v1) | Current Best |
|--------|---------------|--------------|
| **Dice Coefficient** | 0.9275 | _(depends on training)_ |
| **IoU** | 0.8865 | _(depends on training)_ |
| **Parameters** | 1,965,569 | 1,965,569 |
| **Model Size** | 7.6 MB | 7.6 MB |

**Framework:** PyTorch
**Architecture:** Enhanced U-Net [(Ronneberger et al., 2015)](https://arxiv.org/abs/1505.04597)

---

## ğŸ”„ Workflows

| Workflow | Purpose | Trigger | Duration |
|----------|---------|---------|----------|
| **Train Model** | Main training pipeline | PR to main | ~10 min |
| **Data QA** | Validate data quality | PR to main | ~30 sec |
| **Data Upload** | Version data, create PR | Push to `data/*` | ~1 min |
| **CI Pipeline** | Lint and test | Every PR | ~2 min |
| **EC2 Control** | Start/stop infrastructure | Called by other workflows | ~30 sec |

ğŸ‘‰ **[Detailed workflow explanations](docs/WORKFLOWS.md)**

---

## ğŸ› ï¸ Technology Stack

| Layer | Technology |
|-------|-----------|
| **ML Framework** | PyTorch |
| **Experiment Tracking** | MLflow |
| **Data Versioning** | DVC + S3 |
| **Infrastructure** | AWS (EC2, S3, ECR) |
| **IaC** | Terraform |
| **Container Orchestration** | k3s (lightweight Kubernetes) |
| **CI/CD** | GitHub Actions |
| **Deployment** | Helm (future) |

---

## ğŸ’° Cost Breakdown

**Current (with ephemeral infrastructure):**
- EC2 (t3.large, ephemeral): ~$2-3/month
- S3 storage: ~$1/month
- **Total: ~$4/month**

**Traditional (24/7 EC2):**
- EC2 (t3.large, always on): ~$15/month
- S3 storage: ~$1/month
- **Total: ~$18/month**

**Savings: 70-80%**

ğŸ‘‰ **[Architecture details](docs/ARCHITECTURE.md)**

---

## ğŸ¯ Core Flow

```mermaid
graph TD
    A[User: Upload Data] --> B[Data QA]
    B -->|PASS| C[Create PR]
    B -->|FAIL| Z[Error Comment]
    C --> D[Start EC2]
    D --> E[Train Attempt 1]
    D --> F[Train Attempt 2]
    D --> G[Train Attempt 3]
    E --> H[Aggregate Results]
    F --> H
    G --> H
    H -->|Improved| I[Promote to Production]
    H -->|Not Improved| J[Reject PR]
    I --> K[Auto-Approve PR]
    K --> L[User: Merge PR]
    H --> M[Stop EC2]
    J --> M
```

---

## ğŸ“Š Project Status

| Phase | Status | Description |
|-------|--------|-------------|
| Phase 1: Data Foundation | âœ… Complete | DVC, data QA scripts |
| Phase 2: Core Scripts | âœ… Complete | Validation, quality gates |
| Phase 3: GitHub Workflows | âœ… Complete | All pipelines implemented |
| Phase 4: Infrastructure | âœ… Complete | Terraform, EC2, MLflow |
| Phase 5: Training Pipeline | âœ… Complete | Ephemeral training with quality gates |
| Phase 6: Deployment | ğŸš§ In Progress | Docker + k3s deployment |
| Phase 7: Documentation | âœ… Complete | Comprehensive docs |
| Phase 8: Monitoring | ğŸ“… Planned | Prometheus + Grafana |
| Phase 9: Thesis Writing | ğŸ“… Planned | Academic documentation |

---

## ğŸš¦ Getting Started

### Prerequisites

- **AWS Account** (AWS Academy Learner Lab for students)
- **GitHub Account**
- **Local Tools:**
  - Python 3.12+
  - Git
  - AWS CLI v2
  - Terraform 1.0+

### Initial Setup

```bash
# 1. Clone repository with submodules
git clone --recurse-submodules https://github.com/Rafallost/Water-Meters-Segmentation-Autimatization.git
cd Water-Meters-Segmentation-Autimatization

# 2. Configure AWS credentials
aws configure
# Or for AWS Academy: Update ~/.aws/credentials with session credentials

# 3. Deploy infrastructure
cd devops/terraform
terraform init
terraform apply

# 4. Configure GitHub Secrets
# AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN

# 5. Install pre-push hook (optional)
cp devops/hooks/pre-push .git/hooks/
chmod +x .git/hooks/pre-push
```

ğŸ‘‰ **[Detailed setup guide](docs/SETUP.md)** _(TODO)_

---

## ğŸ“ˆ Training Results

Training metrics are logged to MLflow and posted as PR comments.

**Example successful training:**

```
## âœ… Training Results (3 attempts)

ğŸ“ˆ MODEL IMPROVED

### Best Result (Attempt 2)
| Metric | Value  | Baseline | Status |
|--------|--------|----------|--------|
| Dice   | 0.9350 | 0.9275   | âœ… +0.81% |
| IoU    | 0.8920 | 0.8865   | âœ… +0.62% |

ğŸš€ Best model promoted to Production
```

Access MLflow UI: `http://<EC2_IP>:5000` (when EC2 is running)

---

## ğŸ› Troubleshooting

### Common Issues

**"Data QA failed - Non-binary mask values"**
- Masks must contain only 0 and 255
- Convert JPG masks to PNG to avoid compression artifacts
- Run `python devops/scripts/data-qa.py WMS/data/training/` locally

**"Training failed - All 3 attempts"**
- Model didn't improve over baseline
- Check if new data is sufficient/correct
- Review training logs in GitHub Actions

**"AWS credentials expired"**
- AWS Academy credentials expire every 4 hours
- Update `~/.aws/credentials` and GitHub Secrets

**"EC2 costs too high"**
- Ensure ephemeral infrastructure is working
- Run `devops/scripts/cleanup-aws.sh` when done

ğŸ‘‰ **[Full troubleshooting guide](docs/USAGE.md#-troubleshooting)**

---

## ğŸ§¹ Cleanup

**IMPORTANT:** Run this when you're done to avoid AWS costs:

```bash
cd devops
bash scripts/cleanup-aws.sh
```

This will:
- Stop EC2 instance
- Empty S3 buckets
- Destroy all Terraform-managed resources

---

## ğŸ“ Repository Structure

```
Water-Meters-Segmentation-Autimatization/
â”œâ”€â”€ WMS/                          # ML code and data
â”‚   â”œâ”€â”€ src/                      # Training, inference scripts
â”‚   â”‚   â”œâ”€â”€ train.py              # Main training script
â”‚   â”‚   â”œâ”€â”€ model.py              # U-Net architecture
â”‚   â”‚   â”œâ”€â”€ dataset.py            # Data loading
â”‚   â”‚   â””â”€â”€ prepareDataset.py     # Data splitting
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ training/             # Training data (Git/DVC)
â”‚   â”‚       â”œâ”€â”€ images/           # Input photos
â”‚   â”‚       â”œâ”€â”€ masks/            # Ground truth masks
â”‚   â”‚       â””â”€â”€ *.dvc             # DVC metadata
â”‚   â”œâ”€â”€ configs/
â”‚   â”‚   â””â”€â”€ train.yaml            # Hyperparameters
â”‚   â”œâ”€â”€ models/                   # Local checkpoints (gitignored)
â”‚   â””â”€â”€ tests/                    # Unit tests
â”œâ”€â”€ .github/workflows/            # CI/CD pipelines
â”‚   â”œâ”€â”€ train.yml                 # â­ Main training workflow
â”‚   â”œâ”€â”€ data-qa.yaml              # Data validation
â”‚   â”œâ”€â”€ data-upload.yaml          # Data versioning + PR creation
â”‚   â”œâ”€â”€ ec2-control.yaml          # Infrastructure start/stop
â”‚   â”œâ”€â”€ ci.yaml                   # Linting and tests
â”‚   â””â”€â”€ data-staging.yaml         # Auto-branch creation
â”œâ”€â”€ docs/                         # ğŸ“š Documentation
â”‚   â”œâ”€â”€ WORKFLOWS.md              # All pipelines explained
â”‚   â”œâ”€â”€ USAGE.md                  # How-to guide
â”‚   â””â”€â”€ ARCHITECTURE.md           # System design
â”œâ”€â”€ devops/                       # ğŸ”§ Infrastructure (submodule)
â”‚   â”œâ”€â”€ terraform/                # IaC
â”‚   â”œâ”€â”€ helm/                     # Kubernetes deployment
â”‚   â”œâ”€â”€ scripts/                  # Automation
â”‚   â”‚   â”œâ”€â”€ data-qa.py            # Data validation
â”‚   â”‚   â”œâ”€â”€ quality-gate.py       # Model comparison
â”‚   â”‚   â””â”€â”€ cleanup-aws.sh        # Resource teardown
â”‚   â”œâ”€â”€ hooks/                    # Git hooks
â”‚   â”œâ”€â”€ PLAN.md                   # Implementation phases
â”‚   â””â”€â”€ CLAUDE.md                 # AI assistant context
â”œâ”€â”€ README.md                     # This file
â””â”€â”€ requirements.txt              # Python dependencies
```

---

## ğŸ“ Academic Context

**Bachelor's Thesis Project**
**Title:** "Application of DevOps Techniques in Implementing Automatic CI/CD Process for Training and Versioning AI Models"

**Objectives:**
1. Compare manual vs. automated ML deployment workflows
2. Demonstrate cost optimization through ephemeral infrastructure
3. Implement quality gates for model versioning
4. Document best practices for ML DevOps

**Key Results:**
- 70% cost reduction through ephemeral EC2 usage
- Automated quality-gated training pipeline
- Comprehensive experiment tracking with MLflow
- Reproducible infrastructure via Terraform

---

## ğŸ¤ Contributing

This is a thesis project, but feedback is welcome!

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is for academic purposes.

---

## ğŸ™ Acknowledgments

- Original U-Net paper: [Ronneberger et al., 2015](https://arxiv.org/abs/1505.04597)
- Course: Fundamentals of Artificial Intelligence
- MLflow, DVC, and Terraform communities

---

## ğŸ“§ Contact

- **GitHub Issues:** [Report bugs or ask questions](https://github.com/Rafallost/Water-Meters-Segmentation-Autimatization/issues)
- **Email:** _(Your email if public)_

---

## ğŸ”— Related Repositories

- **This repo:** [Water-Meters-Segmentation-Autimatization](https://github.com/Rafallost/Water-Meters-Segmentation-Autimatization) (ML code + workflows)
- **Infrastructure repo:** [DevOps-AI-Model-Automatization](https://github.com/Rafallost/DevOps-AI-Model-Automatization) (Terraform, Helm, scripts)
- **Original model repo:** [Water-Meters-Segmentation](https://github.com/Rafallost/Water-Meters-Segmentation) (Baseline, read-only)

---

**â­ If this project helps you, please star it!**
